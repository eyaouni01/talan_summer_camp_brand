#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
G√©n√©rateur d'images via l'API Hugging Face
Version corrig√©e avec gestion d'erreurs am√©lior√©e
"""

import os
import requests
from PIL import Image
import io
import time

class ImageGenerator:
    def __init__(self, hf_token=None):
        """
        Initialise le g√©n√©rateur avec acc√®s √† l'API Hugging Face
        
        Args:
            hf_token (str): Token Hugging Face (optionnel, utilise la variable d'env si None)
        """
        # Token par d√©faut ou depuis l'environnement
        self.hf_token = hf_token or "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"
        
        # Configuration API
        self.api_url = "https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-schnell"
        self.headers = {
            "Authorization": f"Bearer {self.hf_token}"
        }
        
        print("üé® ImageGenerator Hugging Face initialis√©")
        print(f"üîó Mod√®le : black-forest-labs/FLUX.1-schnell")
        print(f"üîë Token configur√© : {'Oui' if self.hf_token else 'Non'}")
    
    def generate_image(self, prompt: str, output_path: str = "generated_image.png", **kwargs):
        """
        G√©n√®re une image via l'API HF √† partir d'un prompt
        
        Args:
            prompt (str): Prompt textuel pour la g√©n√©ration
            output_path (str): Chemin de sauvegarde de l'image
            **kwargs: Arguments suppl√©mentaires (compatibilit√©)
            
        Returns:
            str|None: Chemin de l'image g√©n√©r√©e ou None en cas d'erreur
        """
        print(f"üìù G√©n√©ration pour : {prompt[:100]}...")
        start_time = time.time()
        
        try:
            # Pr√©paration du dossier de sortie
            output_dir = os.path.dirname(output_path)
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)
            
            # Param√®tres de la requ√™te
            payload = {
                "inputs": prompt,
                "parameters": {
                    "num_inference_steps": kwargs.get("num_inference_steps", 4),  # FLUX.1-schnell optimis√© pour 4 steps
                    "guidance_scale": kwargs.get("guidance_scale", 0.0),  # FLUX.1-schnell fonctionne mieux avec guidance_scale=0
                    "width": kwargs.get("width", 1024),
                    "height": kwargs.get("height", 1024)
                }
            }
            
            # Tentative de g√©n√©ration avec retry
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    print(f"üîÑ Tentative {attempt + 1}/{max_retries}...")
                    
                    response = requests.post(
                        self.api_url,
                        headers=self.headers,
                        json=payload,
                        timeout=60
                    )
                    
                    # V√©rification du statut de r√©ponse
                    if response.status_code == 200:
                        # V√©rifier que c'est bien une image
                        if response.headers.get('content-type', '').startswith('image/'):
                            # Traitement de l'image
                            image = Image.open(io.BytesIO(response.content))
                            
                            # Conversion en RGB si n√©cessaire (pour PNG)
                            if image.mode in ('RGBA', 'LA', 'P'):
                                background = Image.new('RGB', image.size, (255, 255, 255))
                                if image.mode == 'P':
                                    image = image.convert('RGBA')
                                background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                                image = background
                            
                            # Sauvegarde avec optimisation
                            image.save(output_path, format='PNG', quality=95, optimize=True)
                            
                            generation_time = time.time() - start_time
                            print(f"‚úÖ Image g√©n√©r√©e : {output_path} ({generation_time:.1f}s)")
                            print(f"üìè Dimensions : {image.size}")
                            
                            return output_path
                        
                        else:
                            # R√©ponse texte (probablement erreur)
                            error_text = response.text
                            print(f"‚ùå Erreur API : {error_text}")
                            
                            # Si le mod√®le est en cours de chargement, attendre
                            if "loading" in error_text.lower() or "warming up" in error_text.lower():
                                wait_time = 20 * (attempt + 1)
                                print(f"‚è≥ Mod√®le en chargement, attente {wait_time}s...")
                                time.sleep(wait_time)
                                continue
                    
                    elif response.status_code == 503:
                        # Service indisponible, retry avec attente
                        wait_time = 10 * (attempt + 1)
                        print(f"‚è≥ Service indisponible, retry dans {wait_time}s...")
                        time.sleep(wait_time)
                        continue
                    
                    else:
                        print(f"‚ùå Erreur HTTP {response.status_code}: {response.text}")
                        if attempt < max_retries - 1:
                            time.sleep(5)
                            continue
                        break
                
                except requests.exceptions.Timeout:
                    print(f"‚è∞ Timeout sur tentative {attempt + 1}")
                    if attempt < max_retries - 1:
                        time.sleep(5)
                        continue
                
                except Exception as e:
                    print(f"‚ùå Erreur requ√™te tentative {attempt + 1}: {e}")
                    if attempt < max_retries - 1:
                        time.sleep(5)
                        continue
                    break
            
            print("‚ùå √âchec de g√©n√©ration apr√®s tous les retries")
            return None
            
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©rale g√©n√©ration image: {e}")
            return None
    
    def generate_batch(self, prompts: list, output_dir: str = "generated_images", **kwargs):
        """
        G√©n√®re un batch d'images via l'API
        
        Args:
            prompts (list): Liste des prompts
            output_dir (str): Dossier de sortie
            **kwargs: Arguments suppl√©mentaires
            
        Returns:
            list: Liste des chemins des images g√©n√©r√©es
        """
        os.makedirs(output_dir, exist_ok=True)
        results = []
        
        print(f"üé® G√©n√©ration de {len(prompts)} images en batch...")
        
        for i, prompt in enumerate(prompts):
            print(f"\nüìù Image {i+1}/{len(prompts)}")
            
            output_path = os.path.join(output_dir, f"image_{i+1:03d}.png")
            result = self.generate_image(prompt, output_path, **kwargs)
            results.append(result)
            
            # Pause entre les g√©n√©rations pour √©viter le rate limiting
            if i < len(prompts) - 1:
                print("‚è≥ Pause 3s entre g√©n√©rations...")
                time.sleep(3)
        
        successful = [r for r in results if r is not None]
        print(f"\nüìä Batch termin√©: {len(successful)}/{len(prompts)} images g√©n√©r√©es")
        
        return results
    
    def unload_model(self):
        """
        M√©thode placeholder pour compatibilit√© (ne fait rien avec l'API)
        """
        print("‚ÑπÔ∏è Aucun mod√®le local √† d√©charger avec l'API Hugging Face")
    
    def test_connection(self):
        """
        Teste la connexion √† l'API Hugging Face
        
        Returns:
            bool: True si la connexion fonctionne
        """
        print("üîç Test de connexion √† l'API...")
        
        try:
            # Test avec un prompt simple
            test_prompt = "simple test image, white background"
            test_path = "test_connection.png"
            
            result = self.generate_image(test_prompt, test_path)
            
            if result and os.path.exists(test_path):
                # Nettoyer le fichier de test
                try:
                    os.remove(test_path)
                except:
                    pass
                
                print("‚úÖ Connexion API fonctionnelle")
                return True
            else:
                print("‚ùå √âchec du test de connexion")
                return False
                
        except Exception as e:
            print(f"‚ùå Erreur test connexion: {e}")
            return False
    
    def get_model_info(self):
        """
        R√©cup√®re les informations sur le mod√®le utilis√©
        
        Returns:
            dict: Informations sur le mod√®le
        """
        return {
            "model_name": "black-forest-labs/FLUX.1-schnell",
            "api_url": self.api_url,
            "type": "diffusion_model",
            "provider": "Hugging Face",
            "optimal_steps": 4,
            "recommended_guidance": 0.0,
            "max_resolution": "1024x1024",
            "supported_formats": ["PNG", "JPEG"]
        }

# Fonctions utilitaires pour la g√©n√©ration d'images
def create_professional_prompt(role: str, style: str = "corporate") -> str:
    """
    Cr√©e un prompt professionnel optimis√© pour un r√¥le donn√©
    
    Args:
        role (str): Le r√¥le professionnel
        style (str): Le style souhait√©
        
    Returns:
        str: Prompt optimis√©
    """
    base_styles = {
        "corporate": "clean corporate office, professional lighting, modern design",
        "tech": "modern tech workspace, multiple monitors, coding environment",
        "creative": "creative studio, inspiring workspace, artistic tools",
        "minimal": "minimalist workspace, clean lines, simple design"
    }
    
    style_desc = base_styles.get(style, base_styles["corporate"])
    
    prompt = f"Professional {role} workspace, {style_desc}, high quality, 4K resolution, professional photography"
    
    return prompt

def test_image_generation():
    """
    Teste l'int√©gration du mod√®le HF avec diff√©rents sc√©narios
    """
    print("üß™ === TEST G√âN√âRATION D'IMAGES ===")
    
    generator = ImageGenerator()
    
    # Test de connexion
    if not generator.test_connection():
        print("‚ùå Impossible de continuer les tests")
        return
    
    # Tests avec diff√©rents prompts
    test_cases = [
        {
            "name": "Data Scientist",
            "prompt": create_professional_prompt("Data Scientist", "tech"),
            "output": "test_output/data_scientist.png"
        },
        {
            "name": "Product Manager", 
            "prompt": create_professional_prompt("Product Manager", "corporate"),
            "output": "test_output/product_manager.png"
        },
        {
            "name": "Designer",
            "prompt": create_professional_prompt("UX Designer", "creative"),
            "output": "test_output/designer.png"
        }
    ]
    
    os.makedirs("test_output", exist_ok=True)
    
    successful_tests = 0
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nüß™ Test {i}/{len(test_cases)}: {test_case['name']}")
        
        result = generator.generate_image(
            test_case["prompt"], 
            test_case["output"]
        )
        
        if result and os.path.exists(result):
            successful_tests += 1
            print(f"‚úÖ Test r√©ussi: {result}")
        else:
            print(f"‚ùå Test √©chou√© pour {test_case['name']}")
    
    print(f"\nüìä R√©sultat des tests: {successful_tests}/{len(test_cases)} r√©ussis")
    
    # Affichage des informations du mod√®le
    model_info = generator.get_model_info()
    print(f"\nüìã Mod√®le utilis√©: {model_info['model_name']}")
    print(f"üîß Steps optimaux: {model_info['optimal_steps']}")
    print(f"üìè R√©solution max: {model_info['max_resolution']}")

if __name__ == "__main__":
    test_image_generation()